
<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="UTF-8">
      <link rel="stylesheet" href="styles.css">
      <title>SSPL @ CSD</title>
   </head>
   <body>
      <div class="container">
         <h1>A Universal Multi-Speaker Multi-Style Text-to-Speech via Disentangled Representation Learning based on Renyi Divergence Minimization</h1>
         <p class="author-names">
            
            
            <span class="author">Dipjyoti Paul</span>
            
            
            <span class="author"> Sankar Mukherjee</span>
            
            
            <span class="author"> Yannis Pantazis </span>
            
            
            <span class="author"> Yannis Stylianou</span>
            
         </p>
         <hr>
         <p class="paragraph"> In this paper, we present a universal multi-speaker, multi-style Text-to-Speech (TTS) synthesis system which is able to generate speech from text with speaker characteristics and speaking style similar to a given reference signal. Training is conducted on non-parallel data and generates voices in an unsupervised manner, i.e., neither style annotation nor speaker label are required. To avoid leaking content information into the style embeddings (referred to as &#34;content leakage&#34;) and leaking speaker information into style embeddings (referred to as &#34;style leakage&#34;) we suggest a novel Renyi Divergence based Disentangled Representation framework through adversarial learning. Similar to mutual information minimization, the proposed approach explicitly estimates via a variational formula and then minimizes the Renyi divergence between the joint distribution and the product of marginals for the content-style and style-speaker pairs. By doing so, content, style and speaker spaces become representative and (ideally) independent of each other. Our proposed system greatly reduces content leakage by improving the word error rate by approximately 17-19% relative to the baseline system. In MOS-speech-quality, the proposed algorithm achieves an improvement of about 16-20% whereas MOS-style-similarly boost up 15% relative performance. </p>
         <hr>
         
         <h3>More tests</h3>
         <div class="audio-container">
            
            <div class="audio-result">
               
               <h4>Fur Elise</h4>
               
               <audio controls>
                  <source src="results/More%20tests/Fur%20Elise_audio1.mp3" type="audio/mpeg">
               </audio>
            </div>
            
         </div>
         <br>
         
      </div>
   </body>
</html>